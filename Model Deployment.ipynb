{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment Example in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim of this notebook is to demonstrate how we can deploy model in production. Following are the steps which I am following below.\n",
    "* Create SQL lite database\n",
    "* Populate IRIS data into created database\n",
    "* Generate Train, Dev and Test datasets\n",
    "* Train and Dev are used to test model performance. This step can be iterated regularly with new data for model maintainance.\n",
    "* Test data will be used as new dataset for which we want to perform prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import sqlite3   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Lite Database creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDatabaseConnection():\n",
    "    fd = os.open('example.db', os.O_CREAT)\n",
    "    conn = sqlite3.connect('example.db')\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table for storing Iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTable():\n",
    "    conn = getDatabaseConnection()\n",
    "    \n",
    "    iris = datasets.load_iris()\n",
    "    \n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Create table\n",
    "    c.execute('''CREATE TABLE iris\n",
    "                 (sepal_length real, sepal_width real, petal_length real, petal_width real, target int)''')\n",
    "    \n",
    "    print(\"....Database Created....\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Iris data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadIrisToDatabase():\n",
    "    conn = getDatabaseConnection()\n",
    "    \n",
    "    c = conn.cursor()\n",
    "    \n",
    "    for i in range(1,iris.data.shape[0]):\n",
    "        c.execute(\"INSERT INTO iris VALUES (%d,%d,%d,%d,%d)\" % (iris.data[i,0],iris.data[i,1],iris.data[i,2],iris.data[i,3], iris.target[i]))\n",
    "    \n",
    "    conn.commit()\n",
    "    print('.... Data Loaded....')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets as Train, Dev and Test\n",
    "\n",
    "Here we are just calling single query to get all data. But in production systems train and dev data will in one table separately and test set will be provided when actual predictions are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDatasets():\n",
    "    df = pd.DataFrame(list(c.execute('SELECT * FROM iris')))\n",
    "    traindevx, testx, traindevy, testy = train_test_split(df.loc[:,:4], df.loc[:,4], test_size=0.2)\n",
    "    trainx, devx, trainy, devy = train_test_split(traindevx, traindevy, test_size=0.3)\n",
    "    return (traindevx, traindevy, devx, devy, testx, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model on Train data set\n",
    "\n",
    "Train and Dev are used to validate model performance over time. This step is iterated in a schuduled way to keep model updated with new datasets.<br>\n",
    "We are using PICKLE here to store model as file in disk. This file will be loaded again in future to work with model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel(trainx, trainy):\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(trainx, trainy)\n",
    "    pickle.dump(model, open('saved_model', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Method\n",
    "\n",
    "We are loaded saved PICKLE file as model and used to return prediction output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictModel(testx):\n",
    "    model = pickle.load(open('saved_model', 'rb'))\n",
    "    pred = model.predict(testx)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy\n",
    "\n",
    "In this step we are printing confusion metrix, precision, recall and accuracy of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkAccuracy(predy, actualy):\n",
    "    con_mat = confusion_matrix(trainy_pred, trainy)\n",
    "    print(con_mat)\n",
    "    precision = precision_score(trainy_pred, trainy, average=None)\n",
    "    recall = recall_score(trainy_pred, trainy, average=None)\n",
    "    accuracy = accuracy_score(trainy_pred, trainy)\n",
    "    print('Precision is {} Recall is {} Accuracy is {}'.format(precision, recall, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Above steps in ACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Database Created....\n",
      ".... Data Loaded....\n"
     ]
    }
   ],
   "source": [
    "createTable()\n",
    "loadIrisToDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sets = createDatasets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_sets[0], data_sets[1] - Train dataset\n",
    "data_sets[2], data_sets[3] - Dev dataset\n",
    "data_sets[4], data_sets[5] - Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainModel(data_sets[0], data_sets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Accuracy on Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 13]]\n",
      "Precision is [ 1.  1.  1.] Recall is [ 1.  1.  1.] Accuracy is 1.0\n"
     ]
    }
   ],
   "source": [
    "pred = predictModel(data_sets[2])\n",
    "checkAccuracy(pred, data_sets[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Accuracy on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0  9]]\n",
      "Precision is [ 1.  1.  1.] Recall is [ 1.  1.  1.] Accuracy is 1.0\n"
     ]
    }
   ],
   "source": [
    "pred = predictModel(data_sets[4])\n",
    "checkAccuracy(pred, data_sets[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
